{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-40d837a054e1>:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-418-40d837a054e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    339\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 341\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    342\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-40d837a054e1>:2 "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Titanic Dataset\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/Titanic.csv',header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns with Null Values\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599|71.2833|  C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|  113803|   53.1| C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|   17463|51.8625|  E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1| PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  113783|  26.55| C103|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId=2, Survived=1, Pclass=1, Name='Cumings, Mrs. John Bradley (Florence Briggs Thayer)', Sex='female', Age=38.0, SibSp=1, Parch=0, Ticket='PC 17599', Fare=71.2833, Cabin='C85', Embarked='C'),\n",
       " Row(PassengerId=4, Survived=1, Pclass=1, Name='Futrelle, Mrs. Jacques Heath (Lily May Peel)', Sex='female', Age=35.0, SibSp=1, Parch=0, Ticket='113803', Fare=53.1, Cabin='C123', Embarked='S'),\n",
       " Row(PassengerId=7, Survived=0, Pclass=1, Name='McCarthy, Mr. Timothy J', Sex='male', Age=54.0, SibSp=0, Parch=0, Ticket='17463', Fare=51.8625, Cabin='E46', Embarked='S'),\n",
       " Row(PassengerId=11, Survived=1, Pclass=3, Name='Sandstrom, Miss. Marguerite Rut', Sex='female', Age=4.0, SibSp=1, Parch=1, Ticket='PP 9549', Fare=16.7, Cabin='G6', Embarked='S'),\n",
       " Row(PassengerId=12, Survived=1, Pclass=1, Name='Bonnell, Miss. Elizabeth', Sex='female', Age=58.0, SibSp=0, Parch=0, Ticket='113783', Fare=26.55, Cabin='C103', Embarked='S')]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]>"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'),\n",
       " ('Survived', 'int'),\n",
       " ('Pclass', 'int'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'double'),\n",
       " ('SibSp', 'int'),\n",
       " ('Parch', 'int'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'double'),\n",
       " ('Cabin', 'string'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the number of passengers under 25\n",
    "df.filter(df.Age < 25).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+---------------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|          Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+---------------+--------+\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1| PP 9549|    16.7|             G6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|  male|19.0|    3|    2|   19950|   263.0|    C23 C25 C27|       S|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|   19950|   263.0|    C23 C25 C27|       S|\n",
      "|         98|       1|     1|Greenfield, Mr. W...|  male|23.0|    0|    1|PC 17759| 63.3583|        D10 D12|       C|\n",
      "|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|   35281| 77.2875|            D26|       S|\n",
      "|        119|       0|     1|Baxter, Mr. Quigg...|  male|24.0|    0|    1|PC 17558|247.5208|        B58 B60|       C|\n",
      "|        137|       1|     1|Newsom, Miss. Hel...|female|19.0|    0|    2|   11752| 26.2833|            D47|       S|\n",
      "|        140|       0|     1|  Giglio, Mr. Victor|  male|24.0|    0|    0|PC 17593|    79.2|            B86|       C|\n",
      "|        152|       1|     1|Pears, Mrs. Thoma...|female|22.0|    1|    0|  113776|    66.6|             C2|       S|\n",
      "|        184|       1|     2|Becker, Master. R...|  male| 1.0|    2|    1|  230136|    39.0|             F4|       S|\n",
      "|        194|       1|     2|Navratil, Master....|  male| 3.0|    1|    1|  230080|    26.0|             F2|       S|\n",
      "|        206|       0|     3|Strom, Miss. Telm...|female| 2.0|    0|    1|  347054| 10.4625|             G6|       S|\n",
      "|        292|       1|     1|Bishop, Mrs. Dick...|female|19.0|    1|    0|   11967| 91.0792|            B49|       C|\n",
      "|        298|       0|     1|Allison, Miss. He...|female| 2.0|    1|    2|  113781|  151.55|        C22 C26|       S|\n",
      "|        306|       1|     1|Allison, Master. ...|  male|0.92|    1|    2|  113781|  151.55|        C22 C26|       S|\n",
      "|        308|       1|     1|Penasco y Castell...|female|17.0|    1|    0|PC 17758|   108.9|            C65|       C|\n",
      "|        311|       1|     1|Hays, Miss. Marga...|female|24.0|    0|    0|   11767| 83.1583|            C54|       C|\n",
      "|        312|       1|     1|Ryerson, Miss. Em...|female|18.0|    2|    2|PC 17608| 262.375|B57 B59 B63 B66|       C|\n",
      "|        330|       1|     1|Hippach, Miss. Je...|female|16.0|    0|    1|  111361| 57.9792|            B18|       C|\n",
      "|        341|       1|     2|Navratil, Master....|  male| 2.0|    1|    1|  230080|    26.0|             F2|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show passengers under 25\n",
    "df.filter(df.Age < 25).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|        avg(Age)|  stddev_samp(Age)|\n",
      "+----------------+------------------+\n",
      "|35.6744262295082|15.643865966849717|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the mean age and Std. dev.\n",
    "from pyspark.sql.functions import mean, stddev\n",
    "\n",
    "df.select(mean(df.Age), stddev(df.Age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the amount of people who embarked from S\n",
    "df.filter(df.Embarked == 'S').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|     Ticket|   Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+-----------+--------+\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|     113803|   53.1|       C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|      17463|51.8625|        E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|    PP 9549|   16.7|         G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|     113783|  26.55|       C103|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|  male|34.0|    0|    0|     248698|   13.0|        D56|       S|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|  male|28.0|    0|    0|     113788|   35.5|         A6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|  male|19.0|    3|    2|      19950|  263.0|C23 C25 C27|       S|\n",
      "|         63|       0|     1|Harris, Mr. Henry...|  male|45.0|    1|    0|      36973| 83.475|        C83|       S|\n",
      "|         67|       1|     2|Nye, Mrs. (Elizab...|female|29.0|    0|    0| C.A. 29395|   10.5|        F33|       S|\n",
      "|         76|       0|     3|Moen, Mr. Sigurd ...|  male|25.0|    0|    0|     348123|   7.65|      F G73|       S|\n",
      "|         89|       1|     1|Fortune, Miss. Ma...|female|23.0|    3|    2|      19950|  263.0|C23 C25 C27|       S|\n",
      "|         93|       0|     1|Chaffee, Mr. Herb...|  male|46.0|    1|    0|W.E.P. 5734| 61.175|        E31|       S|\n",
      "|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|      35281|77.2875|        D26|       S|\n",
      "|        111|       0|     1|Porter, Mr. Walte...|  male|47.0|    0|    0|     110465|   52.0|       C110|       S|\n",
      "|        124|       1|     2| Webber, Miss. Susan|female|32.5|    0|    0|      27267|   13.0|       E101|       S|\n",
      "|        125|       0|     1|White, Mr. Perciv...|  male|54.0|    0|    1|      35281|77.2875|        D26|       S|\n",
      "|        137|       1|     1|Newsom, Miss. Hel...|female|19.0|    0|    2|      11752|26.2833|        D47|       S|\n",
      "|        138|       0|     1|Futrelle, Mr. Jac...|  male|37.0|    1|    0|     113803|   53.1|       C123|       S|\n",
      "|        149|       0|     2|\"Navratil, Mr. Mi...|  male|36.5|    0|    2|     230080|   26.0|         F2|       S|\n",
      "|        152|       1|     1|Pears, Mrs. Thoma...|female|22.0|    1|    0|     113776|   66.6|         C2|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------+-------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the people who embarked from S\n",
    "df.filter(df.Embarked == 'S').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('Survived', 'Sex', 'Embarked', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare')\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datatypes for training\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "categoricalColumns = ['Sex', 'Embarked']\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "label_stringIdx = StringIndexer(inputCol = 'Survived', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "numericCols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaModelWrapper.__del__ at 0x11f65a290>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pyspark/mllib/common.py\", line 142, in __del__\n",
      "    self._sc._gateway.detach(self._java_model)\n",
      "AttributeError: 'MulticlassMetrics' object has no attribute '_sc'\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "df = df.select(selectedCols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RDD = df.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  DenseVector([0.0, 0.0, 1.0, 1.0, 38.0, 1.0, 0.0, 71.2833]),\n",
       "  1,\n",
       "  'female',\n",
       "  'C',\n",
       "  1,\n",
       "  38.0,\n",
       "  1,\n",
       "  0,\n",
       "  71.2833],\n",
       " [0.0,\n",
       "  DenseVector([0.0, 1.0, 0.0, 1.0, 35.0, 1.0, 0.0, 53.1]),\n",
       "  1,\n",
       "  'female',\n",
       "  'S',\n",
       "  1,\n",
       "  35.0,\n",
       "  1,\n",
       "  0,\n",
       "  53.1],\n",
       " [1.0,\n",
       "  DenseVector([1.0, 1.0, 0.0, 1.0, 54.0, 0.0, 0.0, 51.8625]),\n",
       "  0,\n",
       "  'male',\n",
       "  'S',\n",
       "  1,\n",
       "  54.0,\n",
       "  0,\n",
       "  0,\n",
       "  51.8625],\n",
       " [0.0,\n",
       "  DenseVector([0.0, 1.0, 0.0, 3.0, 4.0, 1.0, 1.0, 16.7]),\n",
       "  1,\n",
       "  'female',\n",
       "  'S',\n",
       "  3,\n",
       "  4.0,\n",
       "  1,\n",
       "  1,\n",
       "  16.7],\n",
       " [0.0,\n",
       "  SparseVector(8, {1: 1.0, 3: 1.0, 4: 58.0, 7: 26.55}),\n",
       "  1,\n",
       "  'female',\n",
       "  'S',\n",
       "  1,\n",
       "  58.0,\n",
       "  0,\n",
       "  0,\n",
       "  26.55],\n",
       " [0.0,\n",
       "  DenseVector([1.0, 1.0, 0.0, 2.0, 34.0, 0.0, 0.0, 13.0]),\n",
       "  1,\n",
       "  'male',\n",
       "  'S',\n",
       "  2,\n",
       "  34.0,\n",
       "  0,\n",
       "  0,\n",
       "  13.0],\n",
       " [0.0,\n",
       "  DenseVector([1.0, 1.0, 0.0, 1.0, 28.0, 0.0, 0.0, 35.5]),\n",
       "  1,\n",
       "  'male',\n",
       "  'S',\n",
       "  1,\n",
       "  28.0,\n",
       "  0,\n",
       "  0,\n",
       "  35.5],\n",
       " [1.0,\n",
       "  DenseVector([1.0, 1.0, 0.0, 1.0, 19.0, 3.0, 2.0, 263.0]),\n",
       "  0,\n",
       "  'male',\n",
       "  'S',\n",
       "  1,\n",
       "  19.0,\n",
       "  3,\n",
       "  2,\n",
       "  263.0],\n",
       " [0.0,\n",
       "  DenseVector([0.0, 0.0, 1.0, 1.0, 49.0, 1.0, 0.0, 76.7292]),\n",
       "  1,\n",
       "  'female',\n",
       "  'C',\n",
       "  1,\n",
       "  49.0,\n",
       "  1,\n",
       "  0,\n",
       "  76.7292],\n",
       " [1.0,\n",
       "  DenseVector([1.0, 0.0, 1.0, 1.0, 65.0, 0.0, 1.0, 61.9792]),\n",
       "  0,\n",
       "  'male',\n",
       "  'C',\n",
       "  1,\n",
       "  65.0,\n",
       "  0,\n",
       "  1,\n",
       "  61.9792]]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([2.596, -2.045, -2.5165, 0.0528, 0.0319, -0.1526, 0.7515, -0.0025])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4599496697453724"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7652173913043478\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy of trained model\n",
    "trainingSummary = lrModel.summary\n",
    "print(trainingSummary.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
