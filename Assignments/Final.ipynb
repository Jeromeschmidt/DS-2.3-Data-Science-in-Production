{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Titanic Final\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/Titanic.csv',header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns with Null Values\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599|71.2833|  C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|  113803|   53.1| C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|   17463|51.8625|  E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1| PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  113783|  26.55| C103|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'),\n",
       " ('Survived', 'int'),\n",
       " ('Pclass', 'int'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'double'),\n",
       " ('SibSp', 'int'),\n",
       " ('Parch', 'int'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'double'),\n",
       " ('Cabin', 'string'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('Survived', 'Sex', 'Embarked', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare')\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datatypes for training\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "categoricalColumns = ['Sex', 'Embarked']\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "label_stringIdx = StringIndexer(inputCol = 'Survived', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "numericCols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "df = df.select(selectedCols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RDD = df.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  DenseVector([0.0, 0.0, 1.0, 1.0, 38.0, 1.0, 0.0, 71.2833]),\n",
       "  1,\n",
       "  'female',\n",
       "  'C',\n",
       "  1,\n",
       "  38.0,\n",
       "  1,\n",
       "  0,\n",
       "  71.2833],\n",
       " [0.0,\n",
       "  DenseVector([0.0, 1.0, 0.0, 1.0, 35.0, 1.0, 0.0, 53.1]),\n",
       "  1,\n",
       "  'female',\n",
       "  'S',\n",
       "  1,\n",
       "  35.0,\n",
       "  1,\n",
       "  0,\n",
       "  53.1],\n",
       " [1.0,\n",
       "  DenseVector([1.0, 1.0, 0.0, 1.0, 54.0, 0.0, 0.0, 51.8625]),\n",
       "  0,\n",
       "  'male',\n",
       "  'S',\n",
       "  1,\n",
       "  54.0,\n",
       "  0,\n",
       "  0,\n",
       "  51.8625],\n",
       " [0.0,\n",
       "  DenseVector([0.0, 1.0, 0.0, 3.0, 4.0, 1.0, 1.0, 16.7]),\n",
       "  1,\n",
       "  'female',\n",
       "  'S',\n",
       "  3,\n",
       "  4.0,\n",
       "  1,\n",
       "  1,\n",
       "  16.7],\n",
       " [0.0,\n",
       "  SparseVector(8, {1: 1.0, 3: 1.0, 4: 58.0, 7: 26.55}),\n",
       "  1,\n",
       "  'female',\n",
       "  'S',\n",
       "  1,\n",
       "  58.0,\n",
       "  0,\n",
       "  0,\n",
       "  26.55],\n",
       " [0.0,\n",
       "  DenseVector([1.0, 1.0, 0.0, 2.0, 34.0, 0.0, 0.0, 13.0]),\n",
       "  1,\n",
       "  'male',\n",
       "  'S',\n",
       "  2,\n",
       "  34.0,\n",
       "  0,\n",
       "  0,\n",
       "  13.0],\n",
       " [0.0,\n",
       "  DenseVector([1.0, 1.0, 0.0, 1.0, 28.0, 0.0, 0.0, 35.5]),\n",
       "  1,\n",
       "  'male',\n",
       "  'S',\n",
       "  1,\n",
       "  28.0,\n",
       "  0,\n",
       "  0,\n",
       "  35.5],\n",
       " [1.0,\n",
       "  DenseVector([1.0, 1.0, 0.0, 1.0, 19.0, 3.0, 2.0, 263.0]),\n",
       "  0,\n",
       "  'male',\n",
       "  'S',\n",
       "  1,\n",
       "  19.0,\n",
       "  3,\n",
       "  2,\n",
       "  263.0],\n",
       " [0.0,\n",
       "  DenseVector([0.0, 0.0, 1.0, 1.0, 49.0, 1.0, 0.0, 76.7292]),\n",
       "  1,\n",
       "  'female',\n",
       "  'C',\n",
       "  1,\n",
       "  49.0,\n",
       "  1,\n",
       "  0,\n",
       "  76.7292],\n",
       " [1.0,\n",
       "  DenseVector([1.0, 0.0, 1.0, 1.0, 65.0, 0.0, 1.0, 61.9792]),\n",
       "  0,\n",
       "  'male',\n",
       "  'C',\n",
       "  1,\n",
       "  65.0,\n",
       "  0,\n",
       "  1,\n",
       "  61.9792]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([3.0026, -2.4742, -2.8621, 0.6101, 0.0286, -0.1504, 0.5134, -0.0027])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6919301912592406"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7518248175182481\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy of trained model\n",
    "trainingSummary = lrModel.summary\n",
    "print(trainingSummary.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
